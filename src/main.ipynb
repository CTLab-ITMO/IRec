{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, \"rb\")\n",
    "    for line in g:\n",
    "        yield eval(line)\n",
    "\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient=\"index\")\n",
    "\n",
    "\n",
    "df = getDF(\"../data/meta_Beauty.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../data/reviews_Beauty_5.json\"\n",
    "\n",
    "unique_items = set()\n",
    "unique_users = set()\n",
    "\n",
    "with open(file_name, \"r\") as file:\n",
    "    for line in file:\n",
    "        review = json.loads(line.strip())\n",
    "        unique_items.add(review[\"asin\"])\n",
    "        unique_users.add(review[\"reviewerID\"])\n",
    "\n",
    "print(f\"Number of unique items: {len(unique_items)}\")\n",
    "print(f\"Number of unique users: {len(unique_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"asin\"].isin(unique_items)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"google-t5/t5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row: pd.Series):\n",
    "    row = row.fillna(\"unknown\")  # empty?\n",
    "    # remove column description / title / cat?\n",
    "    return f\"Description: {row['description']}. Title: {row['title']}. Categories: {', '.join(row['categories'][0])}\"\n",
    "\n",
    "\n",
    "df[\"combined_text\"] = df.apply(preprocess, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True).to(device)\n",
    "\n",
    "    output = model.encoder(\n",
    "        input_ids=enc[\"input_ids\"],\n",
    "        attention_mask=enc[\"attention_mask\"],\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    embeddings = output.last_hidden_state.mean(\n",
    "        dim=1\n",
    "    ).squeeze()  # mean over all tokens (mb CLS?)\n",
    "\n",
    "    return embeddings.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "with torch.no_grad():\n",
    "    df[\"embeddings\"] = df[\"combined_text\"].progress_apply(encode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.stack(df[\"embeddings\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from rqvae import RQVAE\n",
    "\n",
    "\n",
    "rqvae = RQVAE(\n",
    "    input_dim=embs.shape[1],\n",
    "    hidden_dim=128,\n",
    "    beta=0.25,\n",
    "    codebook_sizes=[256] * 4,\n",
    "    should_init_codebooks=False,\n",
    "    should_reinit_unused_clusters=False,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "embs = {\"embedding\": embs.to(device)}\n",
    "\n",
    "rqvae.forward(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cb_tuples(embeddings):\n",
    "    ind_lists = []\n",
    "    for cb in rqvae.codebooks:\n",
    "        dist = torch.cdist(rqvae.encoder(embeddings), cb)\n",
    "        ind_lists.append(dist.argmin(dim=-1).cpu().numpy())\n",
    "\n",
    "    return zip(*ind_lists)\n",
    "\n",
    "\n",
    "def search_similar_items(items_with_tuples, clust2search):\n",
    "    random.shuffle(items_with_tuples)\n",
    "    cnt = 0\n",
    "    similars = []\n",
    "    for item, clust_tuple in items_with_tuples:\n",
    "        if clust_tuple[: len(clust2search)] == clust2search:\n",
    "            similars.append((item, clust_tuple))\n",
    "            cnt += 1\n",
    "        if cnt >= 5:\n",
    "            return similars\n",
    "    return similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_tuples = get_cb_tuples(embs[\"embedding\"])\n",
    "items_with_tuples = list(zip(df[\"title\"], cb_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100, 120):\n",
    "    sim = search_similar_items(items_with_tuples, (i,))\n",
    "    if len(sim) == 0:\n",
    "        continue\n",
    "    print(i)\n",
    "    for item, clust_tuple in sim:\n",
    "        print(f\"{item=} {clust_tuple=}\")\n",
    "\n",
    "# TODO fix collisisons (remainder = last embedding, auto-increment 4th id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2 3 0\n",
    "# 1 2 3 1\n",
    "# 4 5 6 0/2\n",
    "# 4 5 6 1/3\n",
    "\n",
    "# Research last index aggregation\n",
    "\n",
    "# 1) last index = KMeans(last residuals, n=|last codebook|) - collision\n",
    "# 2) auto increment last index (check paper)\n",
    "# 3) decoder\n",
    "# 4) [(1 2 3), (1 2 3)] single item -> ok\n",
    "# 4.1) several -> get embeddings -> score. softmax(collisions), torch.logsoftmax(logits) -> score -> argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos emb for item & codebook (000 111 222) - item\n",
    "# codebook (012 012 012)\n",
    "# splitting item ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(df, \"../data/df_with_embs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
