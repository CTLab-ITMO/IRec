{
  "experiment_name": "tiger_beauty",
  "train_steps_num": 5000,
  "dataset": {
    "type": "rqvae",
    "path_to_data_dir": "../data",
    "name": "Beauty",
    "samplers": {
      "type": "identity"
    }
  },
  "dataloader": {
    "train": {
      "type": "torch",
      "batch_size": 128,
      "batch_processor": {
        "type": "embed"
      },
      "drop_last": false,
      "shuffle": true
    },
    "validation": {
      "type": "torch",
      "batch_size": 256,
      "batch_processor": {
        "type": "embed"
      },
      "drop_last": false,
      "shuffle": false
    }
  },
  "model": {
    "emb_dim": 512,
    "n_tokens": 256,
    "n_codebooks": 4,
    "nhead": 8,
    "num_encoder_layers": 6,
    "num_decoder_layers": 6,
    "dim_feedforward": 2048,
    "dropout": 0.1
  },
  "rqvae_checkpoint_path": "../checkpoints/rqvae_beauty_final_state.pth",
  "rqvae_train_config_path": "../configs/train/rqvae_train_config.json",
  "optimizer": {
    "type": "basic",
    "optimizer": {
      "type": "adam",
      "lr": 1e-4
    },
    "clip_grad_threshold": 5.0,
    "scheduler": {
      "type": "step",
      "step_size": 100, 
      "gamma": 0.98
    }
  },
  "loss": {
    "type": "rqvae_loss",
    "beta": 0.25,
    "output_prefix": "loss"
  },
  "callback": {
    "type": "composite",
    "callbacks": [
      {
        "type": "metric",
        "on_step": 1,
        "loss_prefix": "loss"
      }
    ]
  }
}
