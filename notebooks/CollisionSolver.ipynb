{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from typing import List, Tuple, Dict\n",
        "import torch"
      ],
      "metadata": {
        "id": "CH-xb-IDScxO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WH6rvC8BSTD1"
      },
      "outputs": [],
      "source": [
        "class CollisionSolver:\n",
        "    def __init__(self, residual_length, semantic_id_length, device: torch.device = torch.device('cpu')):\n",
        "        \"\"\"\n",
        "        :param residual_length: Длина остатка для каждого semantic_id\n",
        "        :param semantic_id_length: Длина semantic_id (без токена решающего коллизии)\n",
        "        :param device: Устройство\n",
        "        \"\"\"\n",
        "        self._semantic_id_dict = defaultdict(list)\n",
        "        self.residual_length = residual_length\n",
        "        self.semantic_id_length = semantic_id_length\n",
        "        self.device = device\n",
        "\n",
        "    def _to_device(self, tensor: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Перенос тензора на устройство\n",
        "        \"\"\"\n",
        "        if tensor.device != self.device:\n",
        "            tensor = tensor.to(self.device)\n",
        "        return tensor\n",
        "\n",
        "    def add_item(self, semantic_id: List[int] | torch.Tensor, residual: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        Добавляет новый элемент в словарь хранящий semantic_ids с остатками\n",
        "\n",
        "        :param semantic_id: Semantic id (без токена решающего коллизии)\n",
        "        :param residual: Тензор с остатком для данного semantic_id\n",
        "        \"\"\"\n",
        "        if isinstance(semantic_id, torch.Tensor):\n",
        "            semantic_id = semantic_id.tolist()\n",
        "\n",
        "        assert isinstance(residual, torch.Tensor)\n",
        "        assert residual.shape == (self.residual_length,)\n",
        "        assert len(semantic_id) == self.semantic_id_length\n",
        "\n",
        "        residual = self._to_device(residual)\n",
        "        key = tuple(semantic_id)\n",
        "        self._semantic_id_dict[key].append((len(self._semantic_id_dict[key]), residual))\n",
        "\n",
        "\n",
        "    def create_query_candidates_dict(self, semantic_ids: torch.Tensor | List[List[int]], residuals: torch.Tensor | List[List[int]]) -> None:\n",
        "        \"\"\"\n",
        "        Создает словарь, который содержит сгруппирированные по semantic id элементы, к ним добавлены токены решающие коллизии (добавляются по порядку начиная с нуля)\n",
        "\n",
        "        :param semantic_ids: Тензор или список всех semantic_id, полученных из rq-vae (без токенов решающих коллизии)\n",
        "        :param residuals: Тензор или список остатков для каждого semantic_id\n",
        "        \"\"\"\n",
        "        residuals_count = residuals.shape[0] if isinstance(residuals, torch.Tensor) else len(residuals)\n",
        "        semantic_ids_count = semantic_ids.shape[0] if isinstance(semantic_ids, torch.Tensor) else len(semantic_ids)\n",
        "        assert(residuals_count == semantic_ids_count)\n",
        "\n",
        "        if isinstance(residuals, list):\n",
        "            residuals = torch.tensor(residuals, device=self.device)\n",
        "        residuals = self._to_device(residuals)\n",
        "\n",
        "        for semantic_id, residual in zip(semantic_ids, residuals):\n",
        "            self.add_item(semantic_id, residual)\n",
        "\n",
        "    def get_candidates_tensor(self, query_prefixes: List[List[int]]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        :param query_prefixes: [num_prefixes, prefix_len] список из semantic id (без токенов решающих коллизии)\n",
        "\n",
        "        :return: Кортеж из двух тензоров:\n",
        "        - candidates_tensor (размерность: [num_prefixes, max_collisions, residual_dim]): тензор, содержащий остатки кандидатов для каждого префикса\n",
        "          `max_collisions` — максимальное количество кандидатов для каждого префикса\n",
        "        - mask (размерность: [num_prefixes, max_collisions]): Маска для candidates_tensor\n",
        "\n",
        "        Примечание:\n",
        "            Предполагаем что все префиксы из `query_prefixes` уже есть в словаре semantic ids\n",
        "            Если префикс не найден, будет выброшено исключение\n",
        "        \"\"\"\n",
        "        assert isinstance(query_prefixes, list)\n",
        "        assert(self.residual_length == len(self._semantic_id_dict[tuple(query_prefixes[0])][0][1]))\n",
        "        assert(len(query_prefixes[0]) == self.semantic_id_length)\n",
        "\n",
        "        max_collision_len = max(len(x) for x in self._semantic_id_dict.values())\n",
        "        candidates_tensor = torch.zeros(len(query_prefixes), max_collision_len, self.residual_length, dtype=torch.float32, device=self.device)\n",
        "        mask = torch.zeros(len(query_prefixes), max_collision_len, dtype=torch.bool, device=self.device)\n",
        "\n",
        "        for i, semantic_id in enumerate(query_prefixes):\n",
        "            key = tuple(semantic_id)\n",
        "            assert key in self._semantic_id_dict.keys(), f\"Не найдено обьектов с semantic id {key}\" # нужно что-то с этим делать\n",
        "            for j, residual in self._semantic_id_dict[key]: #сохранение порядка\n",
        "                candidates_tensor[i, j] = residual\n",
        "                mask[i, j] = True\n",
        "        return candidates_tensor, mask\n",
        "\n",
        "    def get_semantic_ids(self, query_prefixes: torch.Tensor, query_residuals: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        :param query_prefixes: [num_prefixes, prefix_len] список из semantic id (без токенов решающих коллизии)\n",
        "\n",
        "        :return: semantic_ids: [num_prefixes, prefix_len + 1] список из semantic id с токенами решающие коллизии\n",
        "        \"\"\"\n",
        "        assert isinstance(query_prefixes, torch.Tensor)\n",
        "        assert isinstance(query_residuals, torch.Tensor)\n",
        "        assert(query_prefixes.shape[0] == query_residuals.shape[0])\n",
        "        assert(query_prefixes.shape[1] == self.semantic_id_length)\n",
        "        assert(query_residuals.shape[1] == self.residual_length)\n",
        "\n",
        "        query_prefixes = self._to_device(query_prefixes)\n",
        "        query_residuals = self._to_device(query_residuals)\n",
        "\n",
        "        candidates_tensor, mask = self.get_candidates_tensor(query_prefixes.tolist())\n",
        "\n",
        "        masked_dot_products = torch.einsum('ijk,ik->ij', candidates_tensor, query_residuals).masked_fill(~mask, float('-inf'))\n",
        "        max_indices = torch.argmax(masked_dot_products, dim=1)\n",
        "        best_semantic_ids = torch.concat((query_prefixes, max_indices.unsqueeze(1)), dim=1)\n",
        "        return best_semantic_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Пример использования"
      ],
      "metadata": {
        "id": "AhJgbuGESnWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residual_length = 12\n",
        "semantic_ids_length = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "semantic_ids = torch.tensor([\n",
        "    [1, 2, 3, 0],\n",
        "    [1, 2, 3, 1],\n",
        "    [1, 2, 3, 2],\n",
        "    [1, 2, 3, 3],\n",
        "    [1, 2, 4, 0],\n",
        "    [1, 2, 4, 1],\n",
        "    [1, 2, 4, 2],\n",
        "    [5, 2, 3, 0],\n",
        "    [5, 2, 3, 1],\n",
        "    [5, 2, 3, 2],\n",
        "    [5, 2, 3, 3],\n",
        "    [5, 2, 3, 4],\n",
        "    [5, 2, 3, 5],\n",
        "    [5, 2, 3, 6],\n",
        "    [2, 8, 7, 6],\n",
        "], device=torch.device('cpu'))\n",
        "\n",
        "residuals = torch.rand(semantic_ids.shape[0], residual_length)\n",
        "\n",
        "query_prefixes = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [1, 2, 4],\n",
        "    [5, 2, 3]\n",
        "], device=device)  # [num_prefixes, prefix_len]\n",
        "\n",
        "query_residuals = torch.rand(query_prefixes.shape[0], residual_length, device=torch.device('cpu'))  # [num_prefixes, emb_dim]"
      ],
      "metadata": {
        "id": "pBjXwVLVSWMO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solver = CollisionSolver(residual_length, semantic_ids_length)\n",
        "\n",
        "solver.create_query_candidates_dict(semantic_ids[:, :-1], residuals)\n",
        "\n",
        "solver.get_semantic_ids(query_prefixes, query_residuals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn7Uk8V_TgrE",
        "outputId": "540b25c6-63bc-4613-90b1-5510ea4d6224"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 2],\n",
              "        [1, 2, 4, 0],\n",
              "        [5, 2, 3, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solver._semantic_id_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HTju2grZm-F",
        "outputId": "442795a8-a952-466c-8c48-fb3d6f14bc81"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {(1,\n",
              "              2,\n",
              "              3): [(0,\n",
              "               tensor([0.2521, 0.4989, 0.8696, 0.9459, 0.4614, 0.3054, 0.1708, 0.8725, 0.5294,\n",
              "                       0.7386, 0.8668, 0.9158])), (1,\n",
              "               tensor([0.3066, 0.7874, 0.8942, 0.5829, 0.5947, 0.1307, 0.1789, 0.7914, 0.6617,\n",
              "                       0.7250, 0.4264, 0.6968])), (2,\n",
              "               tensor([0.8502, 0.4814, 0.2935, 0.2933, 0.5334, 0.5938, 0.4865, 0.7920, 0.9304,\n",
              "                       0.4737, 0.4883, 0.9769])), (3,\n",
              "               tensor([0.4382, 0.4937, 0.5311, 0.1205, 0.0210, 0.2097, 0.7704, 0.9061, 0.6019,\n",
              "                       0.9187, 0.3894, 0.1716]))],\n",
              "             (1,\n",
              "              2,\n",
              "              4): [(0,\n",
              "               tensor([0.9046, 0.2291, 0.9002, 0.7236, 0.7392, 0.1195, 0.0039, 0.1333, 0.2854,\n",
              "                       0.3425, 0.9413, 0.6365])), (1,\n",
              "               tensor([0.3013, 0.1465, 0.4424, 0.9448, 0.0412, 0.5664, 0.3587, 0.1531, 0.5751,\n",
              "                       0.8052, 0.0830, 0.5028])), (2,\n",
              "               tensor([0.9886, 0.6681, 0.4602, 0.3818, 0.8741, 0.3990, 0.1009, 0.8240, 0.9018,\n",
              "                       0.1647, 0.0799, 0.0188]))],\n",
              "             (5,\n",
              "              2,\n",
              "              3): [(0,\n",
              "               tensor([0.6242, 0.6769, 0.8397, 0.6340, 0.9251, 0.2997, 0.9545, 0.6810, 0.4468,\n",
              "                       0.3179, 0.5830, 0.2547])), (1,\n",
              "               tensor([0.9159, 0.3269, 0.6216, 0.8065, 0.9175, 0.3175, 0.0664, 0.1575, 0.1457,\n",
              "                       0.6718, 0.7908, 0.2829])), (2,\n",
              "               tensor([0.1270, 0.7954, 0.7779, 0.9226, 0.0595, 0.6361, 0.4578, 0.7727, 0.4038,\n",
              "                       0.6136, 0.8738, 0.6714])), (3,\n",
              "               tensor([0.0647, 0.4849, 0.2900, 0.4458, 0.3928, 0.1550, 0.6921, 0.8732, 0.7545,\n",
              "                       0.0995, 0.7739, 0.3181])), (4,\n",
              "               tensor([0.2761, 0.3357, 0.2239, 0.4669, 0.9118, 0.2321, 0.7169, 0.5600, 0.5067,\n",
              "                       0.4533, 0.6332, 0.6862])), (5,\n",
              "               tensor([0.9039, 0.0986, 0.9541, 0.7187, 0.6052, 0.8883, 0.1887, 0.1329, 0.3411,\n",
              "                       0.9943, 0.0430, 0.0611])), (6,\n",
              "               tensor([0.7541, 0.7320, 0.2690, 0.1116, 0.0751, 0.7047, 0.5125, 0.9484, 0.2797,\n",
              "                       0.5430, 0.9255, 0.6738]))],\n",
              "             (2,\n",
              "              8,\n",
              "              7): [(0,\n",
              "               tensor([0.6241, 0.6990, 0.7154, 0.6228, 0.1982, 0.0796, 0.1684, 0.9888, 0.0580,\n",
              "                       0.7725, 0.8443, 0.4938]))]})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Альтернативное решение только через torch"
      ],
      "metadata": {
        "id": "ji7PzyQeTxuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_ids = semantic_ids.to(device)\n",
        "residuals = residuals.to(device)\n",
        "query_prefixes = query_prefixes.to(device)\n",
        "query_residuals = query_residuals.to(device)\n",
        "\n",
        "batch_size, max_length = semantic_ids.shape\n",
        "num_prefixes, prefix_len = query_prefixes.shape\n",
        "\n",
        "#привожу к одной размерности чтобы найти совпадения по префиксам\n",
        "semantic_ids_exp = semantic_ids[:, :prefix_len].unsqueeze(0).expand(num_prefixes, batch_size, prefix_len) # [num_prefixes, batch_size, prefix_len]\n",
        "prefixes_exp = query_prefixes.unsqueeze(1).expand(num_prefixes, batch_size, prefix_len) #torch.tile\n",
        "is_prefix_match = (semantic_ids_exp == prefixes_exp).all(dim=2)  # [num_prefixes, batch_size]\n",
        "\n",
        "# Шаг 2: Маскирование residuals для каждого префикса\n",
        "residuals_exp = residuals.unsqueeze(0).expand(num_prefixes, batch_size, -1)  # [num_prefixes, batch_size, emb_dim]\n",
        "masked_residuals = residuals_exp * is_prefix_match.unsqueeze(2).float()  # Зануляем строки, не соответствующие префиксам\n",
        "dot_products = torch.einsum('ijk,ik->ij', masked_residuals, query_residuals)\n",
        "max_indices = torch.argmax(dot_products, dim=1)  # [num_prefixes] #\n",
        "\n",
        "best_semantic_ids = semantic_ids[max_indices]  # [num_prefixes, max_length]\n",
        "best_residuals = residuals[max_indices]  # [num_prefixes, emb_dim]\n",
        "\n",
        "\n",
        "for i, prefix in enumerate(query_prefixes):\n",
        "    print(f\"Префикс: {prefix.tolist()}\")\n",
        "    print(f\"Лучший semantic_id: {best_semantic_ids[i].tolist()}\")\n",
        "    print(f\"Соответствующий residual: {best_residuals[i]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh7jwIkHTr4_",
        "outputId": "d9bccfba-c12f-4036-8bd3-0ef5d1d5b5e1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Префикс: [1, 2, 3]\n",
            "Лучший semantic_id: [1, 2, 3, 2]\n",
            "Соответствующий residual: tensor([0.8502, 0.4814, 0.2935, 0.2933, 0.5334, 0.5938, 0.4865, 0.7920, 0.9304,\n",
            "        0.4737, 0.4883, 0.9769], device='cuda:0')\n",
            "Префикс: [1, 2, 4]\n",
            "Лучший semantic_id: [1, 2, 4, 0]\n",
            "Соответствующий residual: tensor([0.9046, 0.2291, 0.9002, 0.7236, 0.7392, 0.1195, 0.0039, 0.1333, 0.2854,\n",
            "        0.3425, 0.9413, 0.6365], device='cuda:0')\n",
            "Префикс: [5, 2, 3]\n",
            "Лучший semantic_id: [5, 2, 3, 6]\n",
            "Соответствующий residual: tensor([0.7541, 0.7320, 0.2690, 0.1116, 0.0751, 0.7047, 0.5125, 0.9484, 0.2797,\n",
            "        0.5430, 0.9255, 0.6738], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}