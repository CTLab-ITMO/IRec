{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CH-xb-IDScxO"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from typing import List, Tuple, Dict\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WH6rvC8BSTD1"
      },
      "outputs": [],
      "source": [
        "class CollisionSolver:\n",
        "    def __init__(self, residual_length, semantic_id_length, device: torch.device = torch.device('cpu')):\n",
        "        \"\"\"\n",
        "        :param residual_length: Длина остатка для каждого semantic_id\n",
        "        :param semantic_id_length: Длина semantic_id (без токена решающего коллизии)\n",
        "        :param device: Устройство\n",
        "        \"\"\"\n",
        "        self._semantic_id_dict = defaultdict(list)\n",
        "        self.residual_length = residual_length\n",
        "        self.semantic_id_length = semantic_id_length\n",
        "        self.device = device\n",
        "\n",
        "    def _to_device(self, tensor: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Перенос тензора на устройство\n",
        "        \"\"\"\n",
        "        if tensor.device != self.device:\n",
        "            tensor = tensor.to(self.device)\n",
        "        return tensor\n",
        "\n",
        "    def add_item(self, semantic_id: List[int] | torch.Tensor, residual: torch.Tensor) -> None:\n",
        "        \"\"\"\n",
        "        Добавляет новый элемент в словарь хранящий semantic_ids с остатками\n",
        "\n",
        "        :param semantic_id: Semantic id (без токена решающего коллизии)\n",
        "        :param residual: Тензор с остатком для данного semantic_id\n",
        "        \"\"\"\n",
        "        if isinstance(semantic_id, torch.Tensor):\n",
        "            semantic_id = semantic_id.tolist()\n",
        "\n",
        "        assert isinstance(residual, torch.Tensor)\n",
        "        assert residual.shape == (self.residual_length,)\n",
        "        assert len(semantic_id) == self.semantic_id_length\n",
        "\n",
        "        residual = self._to_device(residual)\n",
        "        key = tuple(semantic_id)\n",
        "        self._semantic_id_dict[key].append((len(self._semantic_id_dict[key]), residual))\n",
        "\n",
        "\n",
        "    def create_query_candidates_dict(self, semantic_ids: torch.Tensor | List[List[int]], residuals: torch.Tensor | List[List[int]]) -> None:\n",
        "        \"\"\"\n",
        "        Создает словарь, который содержит сгруппирированные по semantic id элементы, к ним добавлены токены решающие коллизии (добавляются по порядку начиная с нуля)\n",
        "\n",
        "        :param semantic_ids: Тензор или список всех semantic_id, полученных из rq-vae (без токенов решающих коллизии)\n",
        "        :param residuals: Тензор или список остатков для каждого semantic_id\n",
        "        \"\"\"\n",
        "        residuals_count = residuals.shape[0] if isinstance(residuals, torch.Tensor) else len(residuals)\n",
        "        semantic_ids_count = semantic_ids.shape[0] if isinstance(semantic_ids, torch.Tensor) else len(semantic_ids)\n",
        "        assert(residuals_count == semantic_ids_count)\n",
        "\n",
        "        if isinstance(residuals, list):\n",
        "            residuals = torch.tensor(residuals, device=self.device)\n",
        "        residuals = self._to_device(residuals)\n",
        "\n",
        "        for semantic_id, residual in zip(semantic_ids, residuals):\n",
        "            self.add_item(semantic_id, residual)\n",
        "\n",
        "    def get_candidates_tensor(self, query_prefixes: List[List[int]]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        :param query_prefixes: [num_prefixes, prefix_len] список из semantic id (без токенов решающих коллизии)\n",
        "\n",
        "        :return: Кортеж из двух тензоров:\n",
        "        - candidates_tensor (размерность: [num_prefixes, max_collisions, residual_dim]): тензор, содержащий остатки кандидатов для каждого префикса\n",
        "          `max_collisions` — максимальное количество кандидатов для каждого префикса\n",
        "        - mask (размерность: [num_prefixes, max_collisions]): Маска для candidates_tensor\n",
        "\n",
        "        Примечание:\n",
        "            Предполагаем что все префиксы из `query_prefixes` уже есть в словаре semantic ids\n",
        "            Если префикс не найден, будет выброшено исключение\n",
        "        \"\"\"\n",
        "        assert isinstance(query_prefixes, list)\n",
        "        assert(self.residual_length == len(self._semantic_id_dict[tuple(query_prefixes[0])][0][1]))\n",
        "        assert(len(query_prefixes[0]) == self.semantic_id_length)\n",
        "\n",
        "        max_collision_len = max(len(x) for x in self._semantic_id_dict.values())\n",
        "        candidates_tensor = torch.zeros(len(query_prefixes), max_collision_len, self.residual_length, dtype=torch.float32, device=self.device)\n",
        "        mask = torch.zeros(len(query_prefixes), max_collision_len, dtype=torch.bool, device=self.device)\n",
        "\n",
        "        for i, semantic_id in enumerate(query_prefixes):\n",
        "            key = tuple(semantic_id)\n",
        "            assert key in self._semantic_id_dict.keys(), f\"Не найдено обьектов с semantic id {key}\" # нужно что-то с этим делать\n",
        "            for j, residual in self._semantic_id_dict[key]: #сохранение порядка\n",
        "                candidates_tensor[i, j] = residual\n",
        "                mask[i, j] = True\n",
        "        return candidates_tensor, mask\n",
        "\n",
        "    def get_semantic_ids(self, query_prefixes: torch.Tensor, query_residuals: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        :param query_prefixes: [num_prefixes, prefix_len] список из semantic id (без токенов решающих коллизии)\n",
        "\n",
        "        :return: semantic_ids: [num_prefixes, prefix_len + 1] список из semantic id с токенами решающие коллизии\n",
        "        \"\"\"\n",
        "        assert isinstance(query_prefixes, torch.Tensor)\n",
        "        assert isinstance(query_residuals, torch.Tensor)\n",
        "        assert(query_prefixes.shape[0] == query_residuals.shape[0])\n",
        "        assert(query_prefixes.shape[1] == self.semantic_id_length)\n",
        "        assert(query_residuals.shape[1] == self.residual_length)\n",
        "\n",
        "        query_prefixes = self._to_device(query_prefixes)\n",
        "        query_residuals = self._to_device(query_residuals)\n",
        "\n",
        "        candidates_tensor, mask = self.get_candidates_tensor(query_prefixes.tolist())\n",
        "\n",
        "        masked_dot_products = torch.einsum('ijk,ik->ij', candidates_tensor, query_residuals).masked_fill(~mask, float('-inf'))\n",
        "        max_indices = torch.argmax(masked_dot_products, dim=1)\n",
        "        best_semantic_ids = torch.concat((query_prefixes, max_indices.unsqueeze(1)), dim=1)\n",
        "        return best_semantic_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhJgbuGESnWd"
      },
      "source": [
        "# Пример использования"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pBjXwVLVSWMO"
      },
      "outputs": [],
      "source": [
        "residual_length = 12\n",
        "semantic_ids_length = 3\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "semantic_ids = torch.tensor([\n",
        "    [1, 2, 3, 0],\n",
        "    [1, 2, 3, 1],\n",
        "    [1, 2, 3, 2],\n",
        "    [1, 2, 3, 3],\n",
        "    [1, 2, 4, 0],\n",
        "    [1, 2, 4, 1],\n",
        "    [1, 2, 4, 2],\n",
        "    [5, 2, 3, 0],\n",
        "    [5, 2, 3, 1],\n",
        "    [5, 2, 3, 2],\n",
        "    [5, 2, 3, 3],\n",
        "    [5, 2, 3, 4],\n",
        "    [5, 2, 3, 5],\n",
        "    [5, 2, 3, 6],\n",
        "    [2, 8, 7, 6],\n",
        "], device=torch.device('cpu'))\n",
        "\n",
        "residuals = torch.rand(semantic_ids.shape[0], residual_length)\n",
        "\n",
        "query_prefixes = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [1, 2, 4],\n",
        "    [5, 2, 3],\n",
        "    [5, 2, 3]\n",
        "], device=device)  # [num_prefixes, prefix_len]\n",
        "\n",
        "query_residuals = torch.rand(query_prefixes.shape[0], residual_length, device=torch.device('cpu'))  # [num_prefixes, emb_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn7Uk8V_TgrE",
        "outputId": "540b25c6-63bc-4613-90b1-5510ea4d6224"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3, 0],\n",
              "        [1, 2, 4, 0],\n",
              "        [5, 2, 3, 0],\n",
              "        [5, 2, 3, 3]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "solver = CollisionSolver(residual_length, semantic_ids_length)\n",
        "\n",
        "solver.create_query_candidates_dict(semantic_ids[:, :-1], residuals)\n",
        "\n",
        "solver.get_semantic_ids(query_prefixes, query_residuals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HTju2grZm-F",
        "outputId": "442795a8-a952-466c-8c48-fb3d6f14bc81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {(1,\n",
              "              2,\n",
              "              3): [(0,\n",
              "               tensor([0.7220, 0.9496, 0.4006, 0.8832, 0.6087, 0.4947, 0.1341, 0.9645, 0.7408,\n",
              "                       0.5972, 0.3433, 0.8700])), (1,\n",
              "               tensor([0.4457, 0.4410, 0.1333, 0.4391, 0.4153, 0.1703, 0.3044, 0.0940, 0.2773,\n",
              "                       0.5258, 0.5838, 0.0273])), (2,\n",
              "               tensor([0.6268, 0.1060, 0.0841, 0.0750, 0.4090, 0.2886, 0.4343, 0.1945, 0.0429,\n",
              "                       0.8477, 0.1418, 0.6465])), (3,\n",
              "               tensor([0.0077, 0.8171, 0.1344, 0.2223, 0.9616, 0.2790, 0.3448, 0.1485, 0.7148,\n",
              "                       0.5900, 0.0154, 0.4752]))],\n",
              "             (1,\n",
              "              2,\n",
              "              4): [(0,\n",
              "               tensor([0.3480, 0.3537, 0.3771, 0.1443, 0.6877, 0.4845, 0.8278, 0.9831, 0.4941,\n",
              "                       0.0682, 0.0900, 0.2485])), (1,\n",
              "               tensor([0.4048, 0.3308, 0.2278, 0.4890, 0.4899, 0.9994, 0.1511, 0.9374, 0.8730,\n",
              "                       0.7538, 0.0409, 0.1444])), (2,\n",
              "               tensor([0.3601, 0.7909, 0.0766, 0.7096, 0.5745, 0.2606, 0.4412, 0.8748, 0.1248,\n",
              "                       0.5816, 0.2185, 0.2352]))],\n",
              "             (5,\n",
              "              2,\n",
              "              3): [(0,\n",
              "               tensor([0.9524, 0.6976, 0.7598, 0.9994, 0.2881, 0.9854, 0.2537, 0.6400, 0.5632,\n",
              "                       0.5768, 0.2833, 0.0570])), (1,\n",
              "               tensor([0.6778, 0.6523, 0.7592, 0.1953, 0.0077, 0.0960, 0.0714, 0.8100, 0.9999,\n",
              "                       0.0407, 0.1231, 0.7192])), (2,\n",
              "               tensor([0.3652, 0.1131, 0.6800, 0.7445, 0.3586, 0.6498, 0.6479, 0.3792, 0.3110,\n",
              "                       0.7605, 0.9031, 0.4177])), (3,\n",
              "               tensor([0.5732, 0.6359, 0.1402, 0.0661, 0.6557, 0.5067, 0.7383, 0.7173, 0.3075,\n",
              "                       0.3920, 0.7497, 0.9602])), (4,\n",
              "               tensor([0.3407, 0.3068, 0.0815, 0.3887, 0.5861, 0.8103, 0.1236, 0.2175, 0.7513,\n",
              "                       0.5872, 0.7065, 0.0919])), (5,\n",
              "               tensor([0.0248, 0.9603, 0.5902, 0.8559, 0.9800, 0.9306, 0.9737, 0.9035, 0.2527,\n",
              "                       0.0049, 0.3355, 0.2858])), (6,\n",
              "               tensor([0.2779, 0.6830, 0.5133, 0.5767, 0.2029, 0.9013, 0.9562, 0.4474, 0.0377,\n",
              "                       0.0205, 0.6822, 0.1314]))],\n",
              "             (2,\n",
              "              8,\n",
              "              7): [(0,\n",
              "               tensor([0.5204, 0.4737, 0.7302, 0.0674, 0.0289, 0.5045, 0.1267, 0.8282, 0.7559,\n",
              "                       0.3856, 0.4455, 0.1655]))]})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "solver._semantic_id_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji7PzyQeTxuP"
      },
      "source": [
        "# Альтернативное решение только через torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh7jwIkHTr4_",
        "outputId": "d9bccfba-c12f-4036-8bd3-0ef5d1d5b5e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Префикс: [1, 2, 3]\n",
            "Лучший semantic_id: [1, 2, 3, 0]\n",
            "Соответствующий residual: tensor([0.7220, 0.9496, 0.4006, 0.8832, 0.6087, 0.4947, 0.1341, 0.9645, 0.7408,\n",
            "        0.5972, 0.3433, 0.8700])\n",
            "Префикс: [1, 2, 4]\n",
            "Лучший semantic_id: [1, 2, 4, 0]\n",
            "Соответствующий residual: tensor([0.3480, 0.3537, 0.3771, 0.1443, 0.6877, 0.4845, 0.8278, 0.9831, 0.4941,\n",
            "        0.0682, 0.0900, 0.2485])\n",
            "Префикс: [5, 2, 3]\n",
            "Лучший semantic_id: [5, 2, 3, 0]\n",
            "Соответствующий residual: tensor([0.9524, 0.6976, 0.7598, 0.9994, 0.2881, 0.9854, 0.2537, 0.6400, 0.5632,\n",
            "        0.5768, 0.2833, 0.0570])\n",
            "Префикс: [5, 2, 3]\n",
            "Лучший semantic_id: [5, 2, 3, 3]\n",
            "Соответствующий residual: tensor([0.5732, 0.6359, 0.1402, 0.0661, 0.6557, 0.5067, 0.7383, 0.7173, 0.3075,\n",
            "        0.3920, 0.7497, 0.9602])\n"
          ]
        }
      ],
      "source": [
        "semantic_ids = semantic_ids.to(device)\n",
        "residuals = residuals.to(device)\n",
        "query_prefixes = query_prefixes.to(device)\n",
        "query_residuals = query_residuals.to(device)\n",
        "\n",
        "batch_size, max_length = semantic_ids.shape\n",
        "num_prefixes, prefix_len = query_prefixes.shape\n",
        "\n",
        "#привожу к одной размерности чтобы найти совпадения по префиксам\n",
        "semantic_ids_exp = semantic_ids[:, :prefix_len].unsqueeze(0).expand(num_prefixes, batch_size, prefix_len) # [num_prefixes, batch_size, prefix_len]\n",
        "prefixes_exp = query_prefixes.unsqueeze(1).expand(num_prefixes, batch_size, prefix_len) #torch.tile\n",
        "is_prefix_match = (semantic_ids_exp == prefixes_exp).all(dim=2)  # [num_prefixes, batch_size]\n",
        "\n",
        "# Шаг 2: Маскирование residuals для каждого префикса\n",
        "residuals_exp = residuals.unsqueeze(0).expand(num_prefixes, batch_size, -1)  # [num_prefixes, batch_size, emb_dim]\n",
        "masked_residuals = residuals_exp * is_prefix_match.unsqueeze(2).float()  # Зануляем строки, не соответствующие префиксам\n",
        "dot_products = torch.einsum('ijk,ik->ij', masked_residuals, query_residuals)\n",
        "max_indices = torch.argmax(dot_products, dim=1)  # [num_prefixes] #\n",
        "\n",
        "best_semantic_ids = semantic_ids[max_indices]  # [num_prefixes, max_length]\n",
        "best_residuals = residuals[max_indices]  # [num_prefixes, emb_dim]\n",
        "\n",
        "for i, prefix in enumerate(query_prefixes):\n",
        "    print(f\"Префикс: {prefix.tolist()}\")\n",
        "    print(f\"Лучший semantic_id: {best_semantic_ids[i].tolist()}\")\n",
        "    print(f\"Соответствующий residual: {best_residuals[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
