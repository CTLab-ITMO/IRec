{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65d7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c514309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_df = '../data/Beauty/ratings_Beauty.csv'\n",
    "df = pl.read_csv(\n",
    "    path_to_df, \n",
    "    has_header=False, \n",
    "    new_columns=['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "    separator=',',\n",
    "    schema_overrides={\n",
    "        \"user_id\": pl.String,\n",
    "        \"item_id\": pl.String,\n",
    "        \"rating\": pl.String,\n",
    "        'timestamp': pl.UInt64\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075f0414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>item_id</th><th>rating</th><th>timestamp</th></tr><tr><td>str</td><td>str</td><td>str</td><td>u64</td></tr></thead><tbody><tr><td>&quot;A39HTATAQ9V7YF&quot;</td><td>&quot;0205616461&quot;</td><td>&quot;5.0&quot;</td><td>1369699200</td></tr><tr><td>&quot;A3JM6GV9MNOF9X&quot;</td><td>&quot;0558925278&quot;</td><td>&quot;3.0&quot;</td><td>1355443200</td></tr><tr><td>&quot;A1Z513UWSAAO0F&quot;</td><td>&quot;0558925278&quot;</td><td>&quot;5.0&quot;</td><td>1404691200</td></tr><tr><td>&quot;A1WMRR494NWEWV&quot;</td><td>&quot;0733001998&quot;</td><td>&quot;4.0&quot;</td><td>1382572800</td></tr><tr><td>&quot;A3IAAVS479H7M7&quot;</td><td>&quot;0737104473&quot;</td><td>&quot;1.0&quot;</td><td>1274227200</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌────────────────┬────────────┬────────┬────────────┐\n",
       "│ user_id        ┆ item_id    ┆ rating ┆ timestamp  │\n",
       "│ ---            ┆ ---        ┆ ---    ┆ ---        │\n",
       "│ str            ┆ str        ┆ str    ┆ u64        │\n",
       "╞════════════════╪════════════╪════════╪════════════╡\n",
       "│ A39HTATAQ9V7YF ┆ 0205616461 ┆ 5.0    ┆ 1369699200 │\n",
       "│ A3JM6GV9MNOF9X ┆ 0558925278 ┆ 3.0    ┆ 1355443200 │\n",
       "│ A1Z513UWSAAO0F ┆ 0558925278 ┆ 5.0    ┆ 1404691200 │\n",
       "│ A1WMRR494NWEWV ┆ 0733001998 ┆ 4.0    ┆ 1382572800 │\n",
       "│ A3IAAVS479H7M7 ┆ 0737104473 ┆ 1.0    ┆ 1274227200 │\n",
       "└────────────────┴────────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0363473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После 1го этапа фильтрации.\n",
      "Количество пользователей: 52374.\n",
      "Количество айтемов: 67345\n",
      "\n",
      "После 2го этапа фильтрации.\n",
      "Количество пользователей: 40226.\n",
      "Количество айтемов: 19369\n",
      "\n",
      "После 3го этапа фильтрации.\n",
      "Количество пользователей: 27501.\n",
      "Количество айтемов: 17041\n",
      "\n",
      "После 4го этапа фильтрации.\n",
      "Количество пользователей: 26116.\n",
      "Количество айтемов: 13727\n",
      "\n",
      "После 5го этапа фильтрации.\n",
      "Количество пользователей: 23746.\n",
      "Количество айтемов: 13318\n",
      "\n",
      "После 6го этапа фильтрации.\n",
      "Количество пользователей: 23436.\n",
      "Количество айтемов: 12562\n",
      "\n",
      "После 7го этапа фильтрации.\n",
      "Количество пользователей: 22787.\n",
      "Количество айтемов: 12458\n",
      "\n",
      "После 8го этапа фильтрации.\n",
      "Количество пользователей: 22705.\n",
      "Количество айтемов: 12247\n",
      "\n",
      "После 9го этапа фильтрации.\n",
      "Количество пользователей: 22505.\n",
      "Количество айтемов: 12224\n",
      "\n",
      "После 10го этапа фильтрации.\n",
      "Количество пользователей: 22480.\n",
      "Количество айтемов: 12153\n",
      "\n",
      "После 11го этапа фильтрации.\n",
      "Количество пользователей: 22408.\n",
      "Количество айтемов: 12140\n",
      "\n",
      "После 12го этапа фильтрации.\n",
      "Количество пользователей: 22401.\n",
      "Количество айтемов: 12116\n",
      "\n",
      "После 13го этапа фильтрации.\n",
      "Количество пользователей: 22374.\n",
      "Количество айтемов: 12114\n",
      "\n",
      "После 14го этапа фильтрации.\n",
      "Количество пользователей: 22372.\n",
      "Количество айтемов: 12103\n",
      "\n",
      "После 15го этапа фильтрации.\n",
      "Количество пользователей: 22364.\n",
      "Количество айтемов: 12103\n",
      "\n",
      "После 16го этапа фильтрации.\n",
      "Количество пользователей: 22364.\n",
      "Количество айтемов: 12101\n",
      "\n",
      "После 17го этапа фильтрации.\n",
      "Количество пользователей: 22363.\n",
      "Количество айтемов: 12101\n",
      "\n",
      "После 18го этапа фильтрации.\n",
      "Количество пользователей: 22363.\n",
      "Количество айтемов: 12101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtering_stage = 0\n",
    "is_changed = True\n",
    "threshold = 5\n",
    "good_users = set()\n",
    "good_items = set()\n",
    "\n",
    "filtered_df = df.clone()\n",
    "\n",
    "while is_changed:\n",
    "    user_counts = filtered_df.group_by(\"user_id\").agg(pl.len().alias(\"user_count\"))\n",
    "    item_counts = filtered_df.group_by(\"item_id\").agg(pl.len().alias(\"item_count\"))\n",
    "\n",
    "    good_users = user_counts.filter(pl.col(\"user_count\") >= threshold).select(\"user_id\")\n",
    "    good_items = item_counts.filter(pl.col(\"item_count\") >= threshold).select(\"item_id\")\n",
    "\n",
    "    old_size = len(filtered_df)\n",
    "\n",
    "    new_df = filtered_df.join(good_users, on=\"user_id\", how=\"inner\")\n",
    "    new_df = new_df.join(good_items, on=\"item_id\", how=\"inner\")\n",
    "\n",
    "    new_size = len(new_df)\n",
    "\n",
    "    print(f'После {filtering_stage + 1}го этапа фильтрации.')\n",
    "    print(f'Количество пользователей: {good_users.shape[0]}.') \n",
    "    print(f'Количество айтемов: {good_items.shape[0]}')\n",
    "    print()\n",
    "    \n",
    "    filtered_df = new_df\n",
    "    is_changed = old_size != new_size\n",
    "    filtering_stage += 1\n",
    "\n",
    "filtered_df = filtered_df.with_columns(new_user_id = pl.col(\"user_id\").rank(\"dense\") - 1)\n",
    "filtered_df = filtered_df.with_columns(new_item_id = pl.col(\"item_id\").rank(\"dense\") - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6a97b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids_mapping = filtered_df.group_by('new_item_id').agg(pl.col('item_id')).select(\n",
    "    pl.col('item_id').list.get(0).alias('old_item_id'), pl.col('new_item_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102906dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.sort([\"new_user_id\", \"timestamp\"])\n",
    "\n",
    "grouped_filtered_df = filtered_df.group_by(\"new_user_id\", maintain_order=True).agg(\n",
    "    pl.all().exclude(\"new_user_id\").exclude('item_id').exclude('user_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3074f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>old_item_id</th><th>new_item_id</th></tr><tr><td>str</td><td>u64</td></tr></thead><tbody><tr><td>&quot;B0076L73BK&quot;</td><td>9307</td></tr><tr><td>&quot;B004SPDEWE&quot;</td><td>7604</td></tr><tr><td>&quot;B001KPEKMS&quot;</td><td>4064</td></tr><tr><td>&quot;B005GMYPJ4&quot;</td><td>8259</td></tr><tr><td>&quot;B00GYB107Q&quot;</td><td>11799</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────┬─────────────┐\n",
       "│ old_item_id ┆ new_item_id │\n",
       "│ ---         ┆ ---         │\n",
       "│ str         ┆ u64         │\n",
       "╞═════════════╪═════════════╡\n",
       "│ B0076L73BK  ┆ 9307        │\n",
       "│ B004SPDEWE  ┆ 7604        │\n",
       "│ B001KPEKMS  ┆ 4064        │\n",
       "│ B005GMYPJ4  ┆ 8259        │\n",
       "│ B00GYB107Q  ┆ 11799       │\n",
       "└─────────────┴─────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_ids_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e8605e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>new_user_id</th><th>rating</th><th>timestamp</th><th>new_item_id</th></tr><tr><td>u64</td><td>list[str]</td><td>list[u64]</td><td>list[u64]</td></tr></thead><tbody><tr><td>0</td><td>[&quot;2.0&quot;, &quot;5.0&quot;, … &quot;3.0&quot;]</td><td>[1405296000, 1405296000, … 1405296000]</td><td>[9839, 11863, … 11155]</td></tr><tr><td>1</td><td>[&quot;3.0&quot;, &quot;4.0&quot;, … &quot;2.0&quot;]</td><td>[1357430400, 1384387200, … 1402790400]</td><td>[3309, 4572, … 58]</td></tr><tr><td>2</td><td>[&quot;5.0&quot;, &quot;5.0&quot;, … &quot;5.0&quot;]</td><td>[1385337600, 1385337600, … 1386892800]</td><td>[4386, 6362, … 10253]</td></tr><tr><td>3</td><td>[&quot;5.0&quot;, &quot;5.0&quot;, … &quot;5.0&quot;]</td><td>[1366416000, 1366416000, … 1368835200]</td><td>[8968, 10130, … 10320]</td></tr><tr><td>4</td><td>[&quot;5.0&quot;, &quot;3.0&quot;, … &quot;3.0&quot;]</td><td>[1351814400, 1364688000, … 1397692800]</td><td>[8935, 8071, … 8823]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────┬─────────────────────────┬─────────────────────────────────┬────────────────────────┐\n",
       "│ new_user_id ┆ rating                  ┆ timestamp                       ┆ new_item_id            │\n",
       "│ ---         ┆ ---                     ┆ ---                             ┆ ---                    │\n",
       "│ u64         ┆ list[str]               ┆ list[u64]                       ┆ list[u64]              │\n",
       "╞═════════════╪═════════════════════════╪═════════════════════════════════╪════════════════════════╡\n",
       "│ 0           ┆ [\"2.0\", \"5.0\", … \"3.0\"] ┆ [1405296000, 1405296000, … 140… ┆ [9839, 11863, … 11155] │\n",
       "│ 1           ┆ [\"3.0\", \"4.0\", … \"2.0\"] ┆ [1357430400, 1384387200, … 140… ┆ [3309, 4572, … 58]     │\n",
       "│ 2           ┆ [\"5.0\", \"5.0\", … \"5.0\"] ┆ [1385337600, 1385337600, … 138… ┆ [4386, 6362, … 10253]  │\n",
       "│ 3           ┆ [\"5.0\", \"5.0\", … \"5.0\"] ┆ [1366416000, 1366416000, … 136… ┆ [8968, 10130, … 10320] │\n",
       "│ 4           ┆ [\"5.0\", \"3.0\", … \"3.0\"] ┆ [1351814400, 1364688000, … 139… ┆ [8935, 8071, … 8823]   │\n",
       "└─────────────┴─────────────────────────┴─────────────────────────────────┴────────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f064e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users count: 22363\n",
      "Items count: 12101\n",
      "Actions count: 198502\n",
      "Avg user history len: 8.876358270357287\n"
     ]
    }
   ],
   "source": [
    "print('Users count:', filtered_df.select('user_id').unique().shape[0])\n",
    "print('Items count:', filtered_df.select('item_id').unique().shape[0])\n",
    "print('Actions count:', filtered_df.shape[0])\n",
    "print('Avg user history len:', np.mean(list(map(lambda x: x[0], grouped_filtered_df.select(pl.col('new_item_id').list.len()).rows()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3fbd3",
   "metadata": {},
   "source": [
    "## Content embedding creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53f51ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>related</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001048791</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51MKP0T4...</td>\n",
       "      <td>[[Books]]</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000143561</td>\n",
       "      <td>{'Movies &amp; TV': 376041}</td>\n",
       "      <td>http://g-ecx.images-amazon.com/images/G/01/x-s...</td>\n",
       "      <td>[[Movies &amp; TV, Movies]]</td>\n",
       "      <td>Everyday Italian (with Giada de Laurentiis), V...</td>\n",
       "      <td>3Pack DVD set - Italian Classics, Parties and ...</td>\n",
       "      <td>12.99</td>\n",
       "      <td>{'also_viewed': ['B0036FO6SI', 'B000KL8ODE', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000037214</td>\n",
       "      <td>{'Clothing': 1233557}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31mCncNu...</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Girls], [Clothing...</td>\n",
       "      <td>Purple Sequin Tiny Dancer Tutu Ballet Dance Fa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.99</td>\n",
       "      <td>{'also_viewed': ['B00JO8II76', 'B00DGN4R1Q', '...</td>\n",
       "      <td>Big Dreams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000032069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51EzU6qu...</td>\n",
       "      <td>[[Sports &amp; Outdoors, Other Sports, Dance, Clot...</td>\n",
       "      <td>Adult Ballet Tutu Cheetah Pink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.89</td>\n",
       "      <td>{'also_bought': ['0000032050', 'B00D0DJAEG', '...</td>\n",
       "      <td>BubuBibi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000031909</td>\n",
       "      <td>{'Toys &amp; Games': 201847}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41xBoP0F...</td>\n",
       "      <td>[[Sports &amp; Outdoors, Other Sports, Dance]]</td>\n",
       "      <td>Girls Ballet Tutu Neon Pink</td>\n",
       "      <td>High quality 3 layer ballet tutu. 12 inches in...</td>\n",
       "      <td>7.00</td>\n",
       "      <td>{'also_bought': ['B002BZX8Z6', 'B00JHONN1S', '...</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                 salesRank  \\\n",
       "0  0001048791        {'Books': 6334800}   \n",
       "1  0000143561   {'Movies & TV': 376041}   \n",
       "2  0000037214     {'Clothing': 1233557}   \n",
       "3  0000032069                       NaN   \n",
       "4  0000031909  {'Toys & Games': 201847}   \n",
       "\n",
       "                                               imUrl  \\\n",
       "0  http://ecx.images-amazon.com/images/I/51MKP0T4...   \n",
       "1  http://g-ecx.images-amazon.com/images/G/01/x-s...   \n",
       "2  http://ecx.images-amazon.com/images/I/31mCncNu...   \n",
       "3  http://ecx.images-amazon.com/images/I/51EzU6qu...   \n",
       "4  http://ecx.images-amazon.com/images/I/41xBoP0F...   \n",
       "\n",
       "                                          categories  \\\n",
       "0                                          [[Books]]   \n",
       "1                            [[Movies & TV, Movies]]   \n",
       "2  [[Clothing, Shoes & Jewelry, Girls], [Clothing...   \n",
       "3  [[Sports & Outdoors, Other Sports, Dance, Clot...   \n",
       "4         [[Sports & Outdoors, Other Sports, Dance]]   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Crucible: Performed by Stuart Pankin, Jero...   \n",
       "1  Everyday Italian (with Giada de Laurentiis), V...   \n",
       "2  Purple Sequin Tiny Dancer Tutu Ballet Dance Fa...   \n",
       "3                     Adult Ballet Tutu Cheetah Pink   \n",
       "4                        Girls Ballet Tutu Neon Pink   \n",
       "\n",
       "                                         description  price  \\\n",
       "0                                                NaN    NaN   \n",
       "1  3Pack DVD set - Italian Classics, Parties and ...  12.99   \n",
       "2                                                NaN   6.99   \n",
       "3                                                NaN   7.89   \n",
       "4  High quality 3 layer ballet tutu. 12 inches in...   7.00   \n",
       "\n",
       "                                             related       brand  \n",
       "0                                                NaN         NaN  \n",
       "1  {'also_viewed': ['B0036FO6SI', 'B000KL8ODE', '...         NaN  \n",
       "2  {'also_viewed': ['B00JO8II76', 'B00DGN4R1Q', '...  Big Dreams  \n",
       "3  {'also_bought': ['0000032050', 'B00D0DJAEG', '...    BubuBibi  \n",
       "4  {'also_bought': ['B002BZX8Z6', 'B00JHONN1S', '...     Unknown  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            df[i] = eval(line)\n",
    "            i += 1\n",
    "\n",
    "    return pd.DataFrame.from_dict(df, orient=\"index\")\n",
    "\n",
    "df = getDF('../data/Beauty/metadata.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03506905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(row: pd.Series):\n",
    "    row = row.fillna(\"None\")\n",
    "    return f\"Title: {row['title']}. Description: {row['description']}. Categories: {', '.join(row['categories'][0])}\"\n",
    "\n",
    "\n",
    "def get_data(metadata_df, item_ids_mapping_df):\n",
    "    filtered_df = metadata_df.join(\n",
    "        item_ids_mapping_df, \n",
    "        left_on=\"asin\", \n",
    "        right_on='old_item_id', \n",
    "        how=\"inner\"\n",
    "    ).select(pl.col('new_item_id'), pl.col('title'), pl.col('description'), pl.col('categories'))\n",
    "    print(filtered_df.shape)\n",
    "    print(filtered_df.head())\n",
    "\n",
    "    filtered_df = filtered_df.to_pandas()\n",
    "    filtered_df[\"combined_text\"] = filtered_df.apply(preprocess, axis=1)\n",
    "\n",
    "    import pickle\n",
    "    file = open('data.pkl', 'wb')\n",
    "    pickle.dump(filtered_df, file)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5556ec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>related</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001048791</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51MKP0T4...</td>\n",
       "      <td>[[Books]]</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000143561</td>\n",
       "      <td>{'Movies &amp; TV': 376041}</td>\n",
       "      <td>http://g-ecx.images-amazon.com/images/G/01/x-s...</td>\n",
       "      <td>[[Movies &amp; TV, Movies]]</td>\n",
       "      <td>Everyday Italian (with Giada de Laurentiis), V...</td>\n",
       "      <td>3Pack DVD set - Italian Classics, Parties and ...</td>\n",
       "      <td>12.99</td>\n",
       "      <td>{'also_viewed': ['B0036FO6SI', 'B000KL8ODE', '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000037214</td>\n",
       "      <td>{'Clothing': 1233557}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31mCncNu...</td>\n",
       "      <td>[[Clothing, Shoes &amp; Jewelry, Girls], [Clothing...</td>\n",
       "      <td>Purple Sequin Tiny Dancer Tutu Ballet Dance Fa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.99</td>\n",
       "      <td>{'also_viewed': ['B00JO8II76', 'B00DGN4R1Q', '...</td>\n",
       "      <td>Big Dreams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000032069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51EzU6qu...</td>\n",
       "      <td>[[Sports &amp; Outdoors, Other Sports, Dance, Clot...</td>\n",
       "      <td>Adult Ballet Tutu Cheetah Pink</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.89</td>\n",
       "      <td>{'also_bought': ['0000032050', 'B00D0DJAEG', '...</td>\n",
       "      <td>BubuBibi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000031909</td>\n",
       "      <td>{'Toys &amp; Games': 201847}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41xBoP0F...</td>\n",
       "      <td>[[Sports &amp; Outdoors, Other Sports, Dance]]</td>\n",
       "      <td>Girls Ballet Tutu Neon Pink</td>\n",
       "      <td>High quality 3 layer ballet tutu. 12 inches in...</td>\n",
       "      <td>7.00</td>\n",
       "      <td>{'also_bought': ['B002BZX8Z6', 'B00JHONN1S', '...</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                 salesRank  \\\n",
       "0  0001048791        {'Books': 6334800}   \n",
       "1  0000143561   {'Movies & TV': 376041}   \n",
       "2  0000037214     {'Clothing': 1233557}   \n",
       "3  0000032069                       NaN   \n",
       "4  0000031909  {'Toys & Games': 201847}   \n",
       "\n",
       "                                               imUrl  \\\n",
       "0  http://ecx.images-amazon.com/images/I/51MKP0T4...   \n",
       "1  http://g-ecx.images-amazon.com/images/G/01/x-s...   \n",
       "2  http://ecx.images-amazon.com/images/I/31mCncNu...   \n",
       "3  http://ecx.images-amazon.com/images/I/51EzU6qu...   \n",
       "4  http://ecx.images-amazon.com/images/I/41xBoP0F...   \n",
       "\n",
       "                                          categories  \\\n",
       "0                                          [[Books]]   \n",
       "1                            [[Movies & TV, Movies]]   \n",
       "2  [[Clothing, Shoes & Jewelry, Girls], [Clothing...   \n",
       "3  [[Sports & Outdoors, Other Sports, Dance, Clot...   \n",
       "4         [[Sports & Outdoors, Other Sports, Dance]]   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Crucible: Performed by Stuart Pankin, Jero...   \n",
       "1  Everyday Italian (with Giada de Laurentiis), V...   \n",
       "2  Purple Sequin Tiny Dancer Tutu Ballet Dance Fa...   \n",
       "3                     Adult Ballet Tutu Cheetah Pink   \n",
       "4                        Girls Ballet Tutu Neon Pink   \n",
       "\n",
       "                                         description  price  \\\n",
       "0                                                NaN    NaN   \n",
       "1  3Pack DVD set - Italian Classics, Parties and ...  12.99   \n",
       "2                                                NaN   6.99   \n",
       "3                                                NaN   7.89   \n",
       "4  High quality 3 layer ballet tutu. 12 inches in...   7.00   \n",
       "\n",
       "                                             related       brand  \n",
       "0                                                NaN         NaN  \n",
       "1  {'also_viewed': ['B0036FO6SI', 'B000KL8ODE', '...         NaN  \n",
       "2  {'also_viewed': ['B00JO8II76', 'B00DGN4R1Q', '...  Big Dreams  \n",
       "3  {'also_bought': ['0000032050', 'B00D0DJAEG', '...    BubuBibi  \n",
       "4  {'also_bought': ['B002BZX8Z6', 'B00JHONN1S', '...     Unknown  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7b4c78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>old_item_id</th><th>new_item_id</th></tr><tr><td>str</td><td>u64</td></tr></thead><tbody><tr><td>&quot;B000TF70J0&quot;</td><td>2230</td></tr><tr><td>&quot;B005KL3B64&quot;</td><td>8390</td></tr><tr><td>&quot;B001KPEKMS&quot;</td><td>4064</td></tr><tr><td>&quot;B004SPDEWE&quot;</td><td>7604</td></tr><tr><td>&quot;B001MHNQYW&quot;</td><td>4195</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────┬─────────────┐\n",
       "│ old_item_id ┆ new_item_id │\n",
       "│ ---         ┆ ---         │\n",
       "│ str         ┆ u64         │\n",
       "╞═════════════╪═════════════╡\n",
       "│ B000TF70J0  ┆ 2230        │\n",
       "│ B005KL3B64  ┆ 8390        │\n",
       "│ B001KPEKMS  ┆ 4064        │\n",
       "│ B004SPDEWE  ┆ 7604        │\n",
       "│ B001MHNQYW  ┆ 4195        │\n",
       "└─────────────┴─────────────┘"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_ids_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ee63838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12101, 4)\n",
      "shape: (5, 4)\n",
      "┌─────────────┬────────────────────────────┬───────────────────────────┬───────────────────────────┐\n",
      "│ new_item_id ┆ title                      ┆ description               ┆ categories                │\n",
      "│ ---         ┆ ---                        ┆ ---                       ┆ ---                       │\n",
      "│ u64         ┆ str                        ┆ str                       ┆ list[list[str]]           │\n",
      "╞═════════════╪════════════════════════════╪═══════════════════════════╪═══════════════════════════╡\n",
      "│ 0           ┆ WAWO 15 Color Professionl  ┆ An extensive range of 15  ┆ [[\"Beauty\", \"Makeup\", …   │\n",
      "│             ┆ Make…                      ┆ multi…                    ┆ \"Conce…                   │\n",
      "│ 1           ┆ Xtreme Brite Brightening   ┆ Xtreme Brite  Brightening ┆ [[\"Beauty\", \"Hair Care\",  │\n",
      "│             ┆ Gel 1…                     ┆ gel …                     ┆ … \"Cr…                    │\n",
      "│ 2           ┆ Prada Candy By Prada Eau   ┆ Prada Candy By Prada Eau  ┆ [[\"Beauty\", \"Fragrance\",  │\n",
      "│             ┆ De Pa…                     ┆ De Pa…                    ┆ … \"Ea…                    │\n",
      "│ 3           ┆ Versace Bright Crystal Eau ┆ Versace Bright Crystal    ┆ [[\"Beauty\", \"Fragrance\",  │\n",
      "│             ┆ de …                       ┆ Perfume…                  ┆ … \"Ea…                    │\n",
      "│ 4           ┆ Stella McCartney Stella    ┆ STELLA For Women By       ┆ [[\"Beauty\", \"Fragrance\",  │\n",
      "│             ┆                            ┆ STELLA MCC…               ┆ … \"Ea…                    │\n",
      "└─────────────┴────────────────────────────┴───────────────────────────┴───────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "get_data(pl.from_pandas(df), item_ids_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a287a48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [05:54<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from transformers import T5Model, T5Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pickle\n",
    "\n",
    "file = open('data.pkl', 'rb')\n",
    "data = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "model_name = \"google-t5/t5-base\"\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = T5Model.from_pretrained(model_name)\n",
    "encoder = model.encoder.to(device)\n",
    "encoder = encoder.eval()\n",
    "\n",
    "\n",
    "class MyDataset:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self._data = list(zip(data.to_dict()['new_item_id'].values(), data.to_dict()['combined_text'].values()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self._data[idx][1]\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", max_length=1280, truncation=True, padding=\"max_length\")\n",
    "        return {\n",
    "            'item_id': self._data[idx][0],\n",
    "            'input_ids': inputs['input_ids'][0],\n",
    "            'attention_mask': inputs['attention_mask'][0]\n",
    "        }\n",
    "    \n",
    "\n",
    "dataset = MyDataset(data)\n",
    "len(dataset)\n",
    "\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, drop_last=False, shuffle=False, num_workers=10)\n",
    "len(loader)\n",
    "\n",
    "\n",
    "new_df = {\n",
    "    'item_id': [],\n",
    "    'embedding': []\n",
    "}\n",
    "\n",
    "for batch in tqdm(loader):\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        outputs = encoder(\n",
    "            input_ids=batch[\"input_ids\"].to(device), \n",
    "            attention_mask=batch[\"attention_mask\"].to(device)\n",
    "        )\n",
    "    \n",
    "        embeddings = outputs.last_hidden_state  # (bs, sl, ed)\n",
    "        embeddings[(~batch[\"attention_mask\"].bool())] = 0. # (bs, sl, ed)\n",
    "\n",
    "    new_df['item_id'] += batch['item_id'].tolist()\n",
    "    new_df['embedding'] += embeddings.mean(dim=1).tolist()  # (bs, ed)\n",
    "\n",
    "\n",
    "file = open('final_data.pkl', 'wb')\n",
    "pickle.dump(new_df, file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82407f",
   "metadata": {},
   "source": [
    "## Leave-one-out split (last item for test, pre-last item for valid, the remaining part for train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5acd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {}\n",
    "with open('../data/Beauty/all_data.txt', 'w') as f:\n",
    "    for user_id, _, _, item_ids in grouped_filtered_df.iter_rows():\n",
    "        json_data[str(user_id)] = item_ids\n",
    "        f.write(' '.join([str(user_id)] + [\n",
    "            str(item_id) for item_id in item_ids\n",
    "        ]))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dee55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../data/Beauty/inter.json', 'w') as f:\n",
    "    json.dump(json_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e4fa0",
   "metadata": {},
   "source": [
    "## Timestamp-based split (80% for train, 10% for valid, and 10% for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_portion = 0.1\n",
    "test_portion = 0.1\n",
    "\n",
    "all_events_timestamp = []\n",
    "for user_id, user_interractions in user_history.items():\n",
    "    for user_interraction in user_interractions:\n",
    "        interractions_ts = user_interraction['timestamp']\n",
    "        all_events_timestamp.append(interractions_ts)\n",
    "\n",
    "all_events_timestamp = sorted(all_events_timestamp)\n",
    "\n",
    "fst_threshold = all_events_timestamp[int(len(all_events_timestamp) * (1.0 - test_portion - valid_portion))]\n",
    "snd_threshold = all_events_timestamp[int(len(all_events_timestamp) * (1.0 - test_portion))]\n",
    "\n",
    "print(f'First train timestamp:\\t{all_events_timestamp[0]}')\n",
    "print(f'First valid timestamp:\\t{fst_threshold}')\n",
    "print(f'First test timestamp:\\t{snd_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4310f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "valid_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for user_id, user_interactions in user_history.items():\n",
    "    train_history = []\n",
    "    history = []\n",
    "    \n",
    "    for user_interaction in user_interactions:\n",
    "        if user_interaction['timestamp'] < fst_threshold: # train event\n",
    "            assert len(history) == 0 or user_interaction['timestamp'] >= history[-1]['timestamp']\n",
    "            train_history.append(user_interaction)\n",
    "        elif user_interaction['timestamp'] < snd_threshold: # valid event\n",
    "            assert user_interaction['timestamp'] >= fst_threshold\n",
    "            if len(history) >= 5:  # remove cold-start users\n",
    "                valid_samples.append({\n",
    "                    'user_id': user_id,\n",
    "                    'history': [x for x in history],\n",
    "                    'next_interaction': user_interaction\n",
    "                })\n",
    "        else:  # test event\n",
    "            assert user_interaction['timestamp'] >= snd_threshold\n",
    "            if len(history) >= 5:  # remove cold-start users\n",
    "                test_samples.append({\n",
    "                    'user_id': user_id,\n",
    "                    'history': [x for x in history],\n",
    "                    'next_interaction': user_interaction\n",
    "                })\n",
    "        history.append(user_interaction)\n",
    "    \n",
    "    if len(train_history) >= 5:  # remove cold-start users\n",
    "        train_samples.append({\n",
    "            'user_id': user_id,\n",
    "            'history': train_history\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_samples), len(valid_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e652e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "with open('../data/Beauty/train.txt', 'w') as f:\n",
    "    for train_sample in train_samples:\n",
    "        f.write(' '.join([str(train_sample['user_id'])] + [\n",
    "            str(user_interaction['item_id']) for user_interaction in sorted(train_sample['history'], key=lambda x: x['timestamp'])\n",
    "        ]))\n",
    "        f.write('\\n')\n",
    "\n",
    "# valid\n",
    "with open('../data/Beauty/valid.txt', 'w') as f:\n",
    "    for valid_sample in valid_samples:\n",
    "        f.write(' '.join([str(valid_sample['user_id'])] + [\n",
    "            str(user_interaction['item_id']) for user_interaction in sorted(valid_sample['history'], key=lambda x: x['timestamp'])\n",
    "        ] + [str(valid_sample['next_interaction']['item_id'])]))\n",
    "        f.write('\\n')\n",
    "\n",
    "# test\n",
    "with open('../data/Beauty/test.txt', 'w') as f:\n",
    "    for test_sample in test_samples:\n",
    "        f.write(' '.join([str(test_sample['user_id'])] + [\n",
    "            str(user_interaction['item_id']) for user_interaction in sorted(test_sample['history'], key=lambda x: x['timestamp'])\n",
    "        ] + [str(test_sample['next_interaction']['item_id'])]))\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
