{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65d7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c514309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_df = '../data/Beauty/ratings_Beauty.csv'\n",
    "df = pd.read_csv(path_to_df, names=['raw_user_id', 'raw_item_id', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f0414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.raw_user_id.max(), df.raw_user_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3182b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = pd.factorize(df.raw_user_id)[0] + 1\n",
    "df.user_id.min(), df.user_id.max(), df.user_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7225ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_id'] = pd.factorize(df.raw_item_id)[0] + 1\n",
    "df.item_id.min(), df.item_id.max(), df.item_id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5755c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    data.append({\n",
    "        'user_id': int(row.user_id),\n",
    "        'item_id': int(row.item_id),\n",
    "        'timestamp': int(row.timestamp)\n",
    "    })\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history = defaultdict(list)\n",
    "item_history = defaultdict(list)\n",
    "\n",
    "for row in tqdm(data):\n",
    "    user_raw_id = row['user_id']\n",
    "    item_raw_id = row['item_id']\n",
    "    interaction_timestamp = row['timestamp']\n",
    "    \n",
    "    user_history[user_raw_id].append({'item_id': item_raw_id, 'timestamp': interaction_timestamp})\n",
    "    item_history[item_raw_id].append({'user_id': user_raw_id, 'timestamp': interaction_timestamp})\n",
    "\n",
    "is_changed = True\n",
    "threshold = 5\n",
    "good_users = set()\n",
    "good_items = set()\n",
    "\n",
    "\n",
    "while is_changed:\n",
    "    old_state = (len(good_users), len(good_items))\n",
    "    \n",
    "    good_users = set()\n",
    "    good_items = set()\n",
    "\n",
    "    for user_id, history in user_history.items():\n",
    "        if len(history) >= threshold:\n",
    "            good_users.add(user_id)\n",
    "\n",
    "    for item_id, history in item_history.items():\n",
    "        if len(history) >= threshold:\n",
    "            good_items.add(item_id)\n",
    "    \n",
    "    user_history = {\n",
    "        user_id: list(filter(lambda x: x['item_id'] in good_items, history))\n",
    "        for user_id, history in user_history.items()\n",
    "    }\n",
    "    \n",
    "    item_history = {\n",
    "        item_id: list(filter(lambda x: x['user_id'] in good_users, history))\n",
    "        for item_id, history in item_history.items()\n",
    "    }\n",
    "    \n",
    "    new_state = (len(good_users), len(good_items))\n",
    "    is_changed = (old_state != new_state)\n",
    "    print(old_state, new_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = {}\n",
    "item_mapping = {}\n",
    "tmp_user_history = defaultdict(list)\n",
    "tmp_item_history = defaultdict(list)\n",
    "\n",
    "for user_id, history in tqdm(user_history.items()):\n",
    "    processed_history = []\n",
    "\n",
    "    for filtered_item in history:\n",
    "        item_id = filtered_item['item_id']\n",
    "        item_timestamp = filtered_item['timestamp']\n",
    "\n",
    "        processed_item_id = item_mapping.get(item_id, len(item_mapping) + 1)\n",
    "        item_mapping[item_id] = processed_item_id\n",
    "\n",
    "        processed_history.append({'item_id': processed_item_id, 'timestamp': item_timestamp})\n",
    "        \n",
    "    if len(processed_history) >= threshold:\n",
    "        processed_user_id = user_mapping.get(user_id, len(user_mapping) + 1)\n",
    "        user_mapping[user_id] = processed_user_id\n",
    "\n",
    "        tmp_user_history[processed_user_id] = sorted(processed_history, key=lambda x: x['timestamp'])\n",
    "\n",
    "    \n",
    "for item_id, history in tqdm(item_history.items()):\n",
    "    processed_history = []\n",
    "\n",
    "    for filtered_user in history:\n",
    "        user_id = filtered_user['user_id']\n",
    "        user_timestamp = filtered_user['timestamp']\n",
    "\n",
    "        processed_user_id = user_mapping.get(user_id, len(user_mapping) + 1)\n",
    "        user_mapping[user_id] = processed_user_id\n",
    "\n",
    "        processed_history.append({'user_id': processed_user_id, 'timestamp': user_timestamp})\n",
    "\n",
    "    if len(processed_history) >= threshold:\n",
    "        processed_item_id = item_mapping.get(item_id, len(item_mapping) + 1)\n",
    "        item_mapping[item_id] = processed_item_id\n",
    "\n",
    "        tmp_item_history[processed_item_id] = sorted(processed_history, key=lambda x: x['timestamp'])\n",
    "\n",
    "user_history = tmp_user_history\n",
    "item_history = tmp_item_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21613615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall dataset statistics\n",
    "print('Users count:', len(user_mapping))\n",
    "print('Items count:', len(item_mapping))\n",
    "print('Actions count:', sum(list(map(lambda x: len(x), user_history.values()))))\n",
    "print('Avg user history len:', np.mean(list(map(lambda x: len(x), user_history.values()))))\n",
    "print('Avg item history len:', np.mean(list(map(lambda x: len(x), item_history.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82407f",
   "metadata": {},
   "source": [
    "## Leave-one-out split (last item for test, pre-last item for valid, the remaining part for train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5acd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/Beauty/all_data.txt', 'w') as f:\n",
    "    for user_id, user_interractions in user_history.items():\n",
    "        f.write(' '.join([str(user_id)] + [\n",
    "            str(item_event['item_id']) for item_event in sorted(user_interractions, key=lambda x: x['timestamp'])\n",
    "        ]))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1e4fa0",
   "metadata": {},
   "source": [
    "## Timestamp-based split (80% for train, 10% for valid, and 10% for test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_portion = 0.1\n",
    "test_portion = 0.1\n",
    "\n",
    "all_events_timestamp = []\n",
    "for user_id, user_interractions in user_history.items():\n",
    "    for user_interraction in user_interractions:\n",
    "        interractions_ts = user_interraction['timestamp']\n",
    "        all_events_timestamp.append(interractions_ts)\n",
    "\n",
    "all_events_timestamp = sorted(all_events_timestamp)\n",
    "\n",
    "fst_threshold = all_events_timestamp[int(len(all_events_timestamp) * (1.0 - test_portion - valid_portion))]\n",
    "snd_threshold = all_events_timestamp[int(len(all_events_timestamp) * (1.0 - test_portion))]\n",
    "\n",
    "print(f'First train timestamp:\\t{all_events_timestamp[0]}')\n",
    "print(f'First valid timestamp:\\t{fst_threshold}')\n",
    "print(f'First test timestamp:\\t{snd_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4310f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "valid_samples = []\n",
    "test_samples = []\n",
    "\n",
    "for user_id, user_interactions in user_history.items():\n",
    "    train_history = []\n",
    "    history = []\n",
    "    \n",
    "    for user_interaction in user_interactions:\n",
    "        if user_interaction['timestamp'] < fst_threshold: # train event\n",
    "            assert len(history) == 0 or user_interaction['timestamp'] >= history[-1]['timestamp']\n",
    "            train_history.append(user_interaction)\n",
    "        elif user_interaction['timestamp'] < snd_threshold: # valid event\n",
    "            assert user_interaction['timestamp'] >= fst_threshold\n",
    "            if len(history) >= 5:  # remove cold-start users\n",
    "                valid_samples.append({\n",
    "                    'user_id': user_id,\n",
    "                    'history': [x for x in history],\n",
    "                    'next_interaction': user_interaction\n",
    "                })\n",
    "        else:  # test event\n",
    "            assert user_interaction['timestamp'] >= snd_threshold\n",
    "            if len(history) >= 5:  # remove cold-start users\n",
    "                test_samples.append({\n",
    "                    'user_id': user_id,\n",
    "                    'history': [x for x in history],\n",
    "                    'next_interaction': user_interaction\n",
    "                })\n",
    "        history.append(user_interaction)\n",
    "    \n",
    "    if len(train_history) >= 5:  # remove cold-start users\n",
    "        train_samples.append({\n",
    "            'user_id': user_id,\n",
    "            'history': train_history\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_samples), len(valid_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e652e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "with open('../data/Beauty/train.txt', 'w') as f:\n",
    "    for train_sample in train_samples:\n",
    "        f.write(' '.join([str(train_sample['user_id'])] + [\n",
    "            str(user_interaction['item_id']) for user_interaction in sorted(train_sample['history'], key=lambda x: x['timestamp'])\n",
    "        ]))\n",
    "        f.write('\\n')\n",
    "\n",
    "# valid\n",
    "with open('../data/Beauty/valid.txt', 'w') as f:\n",
    "    for valid_sample in valid_samples:\n",
    "        f.write(' '.join([str(valid_sample['user_id'])] + [\n",
    "            str(user_interaction['item_id']) for user_interaction in sorted(valid_sample['history'], key=lambda x: x['timestamp'])\n",
    "        ] + [str(valid_sample['next_interaction']['item_id'])]))\n",
    "        f.write('\\n')\n",
    "\n",
    "# test\n",
    "with open('../data/Beauty/test.txt', 'w') as f:\n",
    "    for test_sample in test_samples:\n",
    "        f.write(' '.join([str(test_sample['user_id'])] + [\n",
    "            str(user_interaction['item_id']) for user_interaction in sorted(test_sample['history'], key=lambda x: x['timestamp'])\n",
    "        ] + [str(test_sample['next_interaction']['item_id'])]))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "deduped_mapping = df.drop_duplicates(subset=['item_id', 'raw_item_id'])\n",
    "\n",
    "embs = torch.load('../data/df_with_embs.pt')\n",
    "\n",
    "merged = pd.merge(deduped_mapping, embs, 'inner', left_on='raw_item_id', right_on='asin')\n",
    "merged['item_id'] = merged['item_id'].map(lambda x: item_mapping[x])\n",
    "    \n",
    "assert len(merged) == len(merged.item_id.unique())\n",
    "merged = merged.set_index('item_id')\n",
    "\n",
    "torch.save(merged, '../data/Beauty/data_full.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
